---
layout: post
title:  "Java and JavaScript"
date:   2016-08-30 15:46:52
categories: tech
tags: [js, java]
---

Thereâ€™s a popular saying out in the wild:

> Java is to JavaScript as car is to carpet.

I donâ€™t know where this saying comes from, but Iâ€™ve seen it around a few times.
And itâ€™s quite true.

That said, itâ€™s clear that Java was a primary source of some of JavaScriptâ€™s
misfeatures. Itâ€™s illuminating to look at some of them below.

## A Month in Advance

A date is a human thing. Computers generally keep track of time with timestamps;
a monotonically increasing integer keeping track of the number of time units
elapsed since some epoch. But humans donâ€™t understand what 1472573807691 means,
so we use a more hierarchial system to keep track of time.

With that in mind, what should `new Date(2016, 8, 30)` mean? August 30, 2016, of
course? If only... it actually means 2016-09-30T04:00:00.000Z. This is again
another holdover from one of Javaâ€™s greatest mistakes.

It is really inexcusable to index months starting from zero, and not at the very
least try to maintain consistency by indexing years and days too. It is really a
shame that even having all three fields off by one is a better situation that
having just one field off by one. Even better, we could perhaps realize that
dates are for humans, not computers, and not do any of this silly indexing to
begin withâ€”1 means January, as any five-year-old knows.

In JavaScriptâ€™s defense, pretty few languages have dates that get this right.

## How Long is a Chinese Name

Truth be told, my browser and font (as of present) cannot display these
characters; nor do I know what they mean: ð €€ð €—. What I do know is that there are
two Unicode scalar values there. Count them: 2. If you donâ€™t believe me, letâ€™s
ask the computer:

### Python 2

{% highlight python %}
>>> len(u'ð €€ð €—')
2
{% endhighlight %}

### Python 3

{% highlight python %}
>>> len('ð €€ð €—')
2
{% endhighlight %}

### Julia

{% highlight julia %}
julia> length("ð €€ð €—")
2
{% endhighlight %}

### Ruby

{% highlight ruby %}
irb(main):001:0> 'ð €€ð €—'.length
=> 2
{% endhighlight %}

OK, the pointâ€™s been made. There are clearly two unicode scalar values there.
But JavaScript has a mind of its own:

### JavaScript

{% highlight javascript %}
> 'ð €€ð €—'.length
4
{% endhighlight %}

Donâ€™t get me wrong â€” I love JavaScript â€” but this is a clear WTF. And it has
Java to blame for this behaviour. And Javaâ€™s (understandable, given the lack of
clarity at the time) decision to make its `String` type effectively an array of
unsigned 16-bit integers, is in many ways a reflection of the poor understanding
of [utf-16].

And this is not merely an academic concern. While the characters I used above
are obscure CJK ideographs, there are a whole class of additional non-BMP
characters that cause issues with JavaScriptâ€™s string length counting, including
most emoji. I can only say that I am rather ðŸ˜ž at this poor handling.

## A Label You Canâ€™t Go To

Both Java and JavaScript have a peculiar feature: labels. This is of course not
so strange. C has them too, after all. But neither Java nor JavaScript actually
have a `goto` statement.

This means that labels are practically worthless, except in a single case: You
can `break` (or `continue`) out of a loop that isnâ€™t the innermost one by
identifying it with a label. So much for not having `goto`. After all, breaking
out of arbitrary loops is just about the worst thing you can do with `goto`
statements.

{% highlight javascript %}
mylabel: do {
  do {
    break mylabel;
  } while (false);
} while (false);
{% endhighlight %}

Of course, nobody knows about this feature. And thatâ€™s probably a good thing,
because whenever code is trying to break out of arbitrary loops, thatâ€™s a sign
that the code needs to be refactored.

[utf-16]: http://programmers.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful
